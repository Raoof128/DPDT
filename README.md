# ğŸ›¡ï¸ Data Poisoning Detection Tool

A **production-grade** platform for detecting training data poisoning attacks, backdoor triggers, and assessing model collapse risk.

> âš ï¸ **Safety Notice**: All data is **SYNTHETIC** and **SAFE** for educational purposes. No real malware, attacks, or PII.

---

## âœ¨ Features

### ğŸ”¬ Detection Engines

| Engine | Description |
|--------|-------------|
| **Spectral Signatures** | PCA/SVD-based outlier detection using singular vector analysis |
| **Activation Clustering** | Neural activation analysis with K-Means/DBSCAN |
| **Influence Functions** | Simplified harmful sample estimation |
| **Trigger Detection** | Pixel patches, watermarks, text sequences |

### ğŸ“Š Risk Assessment

- **Overfit Potential**: Dimensionality vs sample ratio
- **Representation Collapse**: Feature variance analysis
- **Class Boundary Distortion**: Inter-class distance metrics
- **Poisoning Density**: Suspicious sample concentration

### ğŸ§¹ Dataset Cleaning

- **STRICT**: Remove all flagged samples
- **SAFE**: Remove high-confidence detections only
- **REVIEW**: Generate suggestions without removal

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- pip or conda

### Installation

```bash
# Clone or navigate to project
cd data-poisoning-detector

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Run the Server

```bash
# Start FastAPI server
python -m backend.main

# Or with uvicorn directly
uvicorn backend.main:app --reload --host 0.0.0.0 --port 8000
```

### Access

- **Dashboard**: http://localhost:8000/dashboard
- **API Docs**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/health

---

## ğŸ“¡ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/scan` | Validate dataset quality |
| `POST` | `/detect_poison` | Run full detection pipeline |
| `POST` | `/clean` | Clean poisoned dataset |
| `POST` | `/collapse_risk` | Assess training risk |
| `POST` | `/report` | Generate HTML report |
| `GET`  | `/health` | Health check |
| `GET`  | `/dashboard` | Web dashboard |

### Example: Detect Poisoning

```bash
curl -X POST http://localhost:8000/detect_poison \
  -H "Content-Type: application/json" \
  -d '{
    "dataset_type": "image",
    "n_samples": 1000,
    "n_classes": 10,
    "poison_ratio": 0.1,
    "run_spectral": true,
    "run_clustering": true,
    "run_influence": true,
    "run_trigger": true
  }'
```

---

## ğŸ—ï¸ Project Structure

```
data-poisoning-detector/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ scan.py             # Dataset scanning
â”‚   â”‚   â”œâ”€â”€ poison.py           # Poisoning detection
â”‚   â”‚   â”œâ”€â”€ clean.py            # Dataset cleaning
â”‚   â”‚   â”œâ”€â”€ collapse.py         # Risk assessment
â”‚   â”‚   â””â”€â”€ report.py           # Report generation
â”‚   â”œâ”€â”€ engines/
â”‚   â”‚   â”œâ”€â”€ ingest_engine.py    # Data ingestion & validation
â”‚   â”‚   â”œâ”€â”€ spectral_engine.py  # Spectral signatures
â”‚   â”‚   â”œâ”€â”€ activation_clustering.py
â”‚   â”‚   â”œâ”€â”€ influence_engine.py
â”‚   â”‚   â”œâ”€â”€ trigger_detector.py
â”‚   â”‚   â”œâ”€â”€ risk_engine.py
â”‚   â”‚   â””â”€â”€ cleanser.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ logger.py           # Logging utilities
â”‚       â”œâ”€â”€ hash_utils.py       # Dataset fingerprinting
â”‚       â”œâ”€â”€ visuals.py          # Visualization
â”‚       â””â”€â”€ pdf_export.py       # Report export
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html              # Dashboard UI
â”‚   â”œâ”€â”€ styles.css              # Premium dark theme
â”‚   â””â”€â”€ dashboard.js            # Interactive features
â”œâ”€â”€ tests/
â”œâ”€â”€ logs/
â”œâ”€â”€ models/
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“– Detection Theory

### Spectral Signatures

Based on [Tran et al., NeurIPS 2018], poisoned samples create separable subspaces in representation space. By analyzing projections onto top singular vectors, we identify outliers.

```
1. Center data matrix X
2. Compute SVD: X = UÎ£V^T
3. Project samples onto top-k singular vectors
4. Flag samples with high projection magnitudes (z-score > threshold)
```

### Activation Clustering

Poisoned samples often cluster separately from clean samples in activation space:

1. Extract intermediate activations
2. Apply K-Means/DBSCAN per class
3. Identify minority clusters as suspicious
4. Cross-reference with label distribution

---

## ğŸ“‹ Compliance Mapping

| Framework | Coverage |
|-----------|----------|
| **NIST AI RMF** | Govern, Map, Measure, Manage functions |
| **ISO/IEC 42001** | AI management system requirements |
| **OAIC ADM** | Automated decision-making transparency |

---

## ğŸ§ª Testing

```bash
# Run tests
pytest tests/ -v

# With coverage
pytest tests/ --cov=backend --cov-report=html
```

---

## ğŸ”’ Safety Rules

1. âœ… Only synthetic datasets
2. âœ… No real malicious triggers
3. âœ… No attack instructions
4. âœ… All examples are benign
5. âœ… Educational purposes only

---

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

- Spectral Signatures: Tran et al., "Spectral Signatures in Backdoor Attacks"
- FastAPI: SebastiÃ¡n RamÃ­rez
- scikit-learn: The scikit-learn developers

---

**Built with ğŸ›¡ï¸ for AI Safety**
